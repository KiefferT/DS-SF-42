{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1\n",
    "\n",
    "In this first project you will create a framework to scope out data science projects. This framework will provide you with a guide to develop a well-articulated problem statement and analysis plan that will be robust and reproducible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and evaluate the following problem statement: \n",
    "Determine which free-tier customers will covert to paying customers, using demographic data collected at signup (age, gender, location, and profession) and customer useage data (days since last log in, and activity score 1 = active user, 0= inactive user) based on Hooli data from Jan-Apr 2015. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What is the outcome?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: customer conversion from free-tier to paying customer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What are the predictors/covariates? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: age, gender, location, profession, days since last log in, activity score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What timeframe is this data relevent for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Jan - Apr 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. What is the hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: using data collected at signup (age, gender, location, and profession) and customer useage data (days since last log in and activity score), we will be able to predict the likelihood that a customer will convert from a free-tier to a paying customer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started with our UCLA admissions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kiefferthomas/anaconda2/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1984)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"admissions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create a data dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Variable | Description | Type of Variable\n",
    "---| ---| ---\n",
    "admit | 1 = admitted 0 = not admitted | binary\n",
    "gre | GRE score | continuous\n",
    "gpa | Grade point average | continuous\n",
    "prestige | Prestige of undergrad (1 = highest prestige, 4 = Lowest) | categorical "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to explore the association between the admit variable and the predictors gre, gpa, and prestige  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What is the outcome?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: admittance to program (admit variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What are the predictors/covariates? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: gre, gpa, and prestige"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. What timeframe is this data relevent for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: NA - No information is given on the timeframe of this hypothetical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What is the hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: given data on an applicant's gre, gpa, and prestige of undergraduate program, a decent estimate of the probability of admittance to the graduate program can be obtained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.Using the above information, write a well-formed problem statement. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Determine the likelihood of admittance to a graduate program using data on a candidate's GRE score, undergraduate GPA, and the prestige of their undergraduate institution, using the UCLA admissions dataset. The dataset is made up of hypothetical data (source data can be obtained [here](https://stats.idre.ucla.edu/stat/data/binary.csv); more information available at https://stats.idre.ucla.edu/r/dae/logit-regression/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Analysis Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the lab from a class as a guide, create an exploratory analysis plan. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What are the goals of the exploratory analysis? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Explore the overall nature of our data: size of dataset, column names and data types, and if there are any null values\n",
    "- Check on frequencies (counts) for our binary and categorical variables\n",
    "- Assess the distributions of our continuous variables\n",
    "- Examine descriptive statistics of our continuous variables and remove any outliers\n",
    "\n",
    "Overall, the goal of the exploratory analysis is to get a good overall picture of the data we are working with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a. What are the assumptions of the distribution of data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: We are assuming the continuous variables in our dataset (gre and gpa) are approximately normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b. How will determine the distribution of your data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer: The easiest way is to simply plot histograms of these variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c12274410>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10df39c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['gpa'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c172c3bd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAE/FJREFUeJzt3X2QXfV93/H3xxKYBz8IwUIVMBF0\nNMSeTgxk4+KQpg6Y1IYESAe3OJ5EzZCobdzGxO3EspuJk5lmBndc42Tasa2EpIprgwGDpYITR1Zw\nMsl0hFegmAdBhbGCZWS0cYKJH2qM8+0f97dmq6x2r4TOvXt13q+ZO+ec3z3nnu8P7t2PznOqCklS\nf71o3AVIksbLIJCknjMIJKnnDAJJ6jmDQJJ6ziCQpJ4zCCSp5wwCSeo5g0CSem7luAsYxmmnnVZr\n164ddxmSNFF27tz5V1U1tdR8ExEEa9euZWZmZtxlSNJESfKXw8znriFJ6jmDQJJ6ziCQpJ4zCCSp\n5wwCSeo5g0CSes4gkKSeMwgkqec6DYIkv5TkoSQPJrk5yQlJzkmyI8meJB9LcnyXNUiSFtfZlcVJ\nzgR+EXhVVX0zya3AtcDlwI1VdUuSDwLXAR/oqg7pWLV2491jWe/eG64Yy3rVna53Da0ETkyyEjgJ\n2A9cAtze3t8MXN1xDZKkRXQWBFX1JeC9wBMMAuCrwE7g6ap6rs22DzhzoeWTbEgyk2Rmdna2qzIl\nqfc6C4IkpwBXAecA3wOcDLxxgVlroeWralNVTVfV9NTUkjfPkyQdoS53Db0e+EJVzVbVt4E7gB8C\nVrVdRQBnAU92WIMkaQldBsETwEVJTkoS4FLgYeAe4Jo2z3pgS4c1SJKW0OUxgh0MDgrfBzzQ1rUJ\neAfw9iSPAacCN3VVgyRpaZ0+mKaq3g28+6Dmx4HXdLleSdLwvLJYknrOIJCknjMIJKnnDAJJ6jmD\nQJJ6ziCQpJ4zCCSp5zq9jkA61o3rVtDS0eQWgST1nEEgST1nEEhSzxkEktRzBoEk9ZxBIEk9ZxBI\nUs8ZBJLUc10+vP68JLvmvZ5Jcn2S1Um2JdnThqd0VYMkaWldPqry0ao6v6rOB34A+AZwJ7AR2F5V\n64DtbVqSNCaj2jV0KfD5qvpL4Cpgc2vfDFw9ohokSQsYVRBcC9zcxs+oqv0AbXj6iGqQJC2g8yBI\ncjxwJXDbYS63IclMkpnZ2dluipMkjWSL4I3AfVX1VJt+KskagDY8sNBCVbWpqqaranpqamoEZUpS\nP40iCN7M87uFALYC69v4emDLCGqQJB1Cp0GQ5CTgMuCOec03AJcl2dPeu6HLGiRJi+v0wTRV9Q3g\n1IPavsLgLCJJ0jLglcWS1HMGgST1nEEgST1nEEhSzxkEktRzBoEk9ZxBIEk9ZxBIUs91ekGZpGPP\n2o13j23de2+4YmzrPpa5RSBJPWcQSFLPGQSS1HMGgST1nEEgST1nEEhSzxkEktRzBoEk9VzXj6pc\nleT2JI8k2Z3ktUlWJ9mWZE8bntJlDZKkxXW9RfCbwB9W1fcBrwZ2AxuB7VW1DtjepiVJY9JZECR5\nGfAjwE0AVfVsVT0NXAVsbrNtBq7uqgZJ0tK63CI4F5gFfi/J/Ul+J8nJwBlVtR+gDU9faOEkG5LM\nJJmZnZ3tsExJ6rcug2AlcCHwgaq6APg6h7EbqKo2VdV0VU1PTU11VaMk9V6XQbAP2FdVO9r07QyC\n4akkawDa8ECHNUiSltBZEFTVl4EvJjmvNV0KPAxsBda3tvXAlq5qkCQtrevnEfx74CNJjgceB36W\nQfjcmuQ64AngTR3XIElaRKdBUFW7gOkF3rq0y/VKkobnlcWS1HMGgST1nEEgST1nEEhSzxkEktRz\nBoEk9ZxBIEk9ZxBIUs8ZBJLUcwaBJPWcQSBJPWcQSFLPGQSS1HMGgST1nEEgST03VBAk+UddFyJJ\nGo9htwg+mOTeJL+QZNWwH55kb5IHkuxKMtPaVifZlmRPG55yRJVLko6KoYKgqn4YeAvwCmAmyUeT\nXDbkOn60qs6vqrknlW0EtlfVOmB7m5YkjcnQxwiqag/wK8A7gH8K/FaSR5L888Nc51XA5ja+Gbj6\nMJeXJB1Fwx4j+P4kNwK7gUuAn6iqV7bxGxdZtIA/SrIzyYbWdkZV7Qdow9OPuHpJ0gs27MPr/xvw\n28C7quqbc41V9WSSX1lkuYvbPKcD25I8MmxhLTg2AJx99tnDLqaeWrvx7nGXIE2sYXcNXQ58dC4E\nkrwoyUkAVfXhQy1UVU+24QHgTuA1wFNJ1rTPWQMcOMSym6pquqqmp6amhu2PJOkwDRsEnwZOnDd9\nUms7pCQnJ3np3DjwY8CDwFZgfZttPbDlcAqWJB1dw+4aOqGqvjY3UVVfm9siWMQZwJ1J5tbz0ar6\nwySfBW5Nch3wBPCmI6hbknSUDBsEX09yYVXdB5DkB4BvLrZAVT0OvHqB9q8Alx5uoZKkbgwbBNcD\ntyV5sk2vAf5lNyVJkkZpqCCoqs8m+T7gPCDAI1X17U4rkySNxLBbBAA/CKxty1yQhKr6/U6qkiSN\nzFBBkOTDwD8EdgHfac0FGASSNOGG3SKYBl5VVdVlMZKk0Rv2OoIHgX/QZSGSpPEYdovgNODhJPcC\n35prrKorO6lKkjQywwbBr3VZhCRpfIY9ffRPknwvsK6qPt2uKl7RbWmSpFEY9jbUPw/cDnyoNZ0J\nfKKroiRJozPsrqG3Mrhz6A4YPKSm3VpakkZmXLcb33vDFWNZ76gMe9bQt6rq2bmJJCsZXEcgSZpw\nwwbBnyR5F3Bie1bxbcD/6q4sSdKoDBsEG4FZ4AHgXwOfZPD8YknShBv2rKG/Y/Coyt/uthxJ0qgN\ne6+hL7DAMYGqOveoVyRJGqnDudfQnBMYPFVs9dEvR5I0akMdI6iqr8x7famq3g9cMsyySVYkuT/J\nXW36nCQ7kuxJ8rEkx7+A+iVJL9CwF5RdOO81neTfAC8dch1vA3bPm34PcGNVrQP+BrjusCqWJB1V\nw+4a+q/zxp8D9gL/YqmFkpwFXAH8BvD2DJ5kfwnwU22WzQzuY/SBIeuQJB1lw5419KNH+PnvB36Z\n57ceTgWerqrn2vQ+BrerkCSNybBnDb19sfer6n0LLPPjwIGq2pnkdXPNCy1+iHVuADYAnH322cOU\nKUk6Aodz1tAPAlvb9E8Afwp8cZFlLgauTHI5gzONXsZgC2FVkpVtq+As4MmFFq6qTcAmgOnpaW9n\nIUkdOZwH01xYVX8LkOTXgNuq6ucOtUBVvRN4Z5v/dcB/rKq3JLkNuAa4BVgPbDni6iVJL9iwt5g4\nG3h23vSzwNojXOc7GBw4fozBMYObjvBzJElHwbBbBB8G7k1yJ4N9+j8J/P6wK6mqzwCfaeOPM7il\ntSRpGRj2rKHfSPIHwD9pTT9bVfd3V5YkaVSG3TUEcBLwTFX9JrAvyTkd1SRJGqFhryx+N4N9++9s\nTccB/7OroiRJozPsFsFPAlcCXweoqicZ/hYTkqRlbNggeLaqinbxV5KTuytJkjRKwwbBrUk+xOBi\nsJ8HPo0PqZGkY8KwZw29tz2r+BngPOBXq2pbp5VJkkZiySBIsgL4VFW9HvCPv6TeWbvx7rGsd+8N\nV4xkPUvuGqqq7wDfSPLyEdQjSRqxYa8s/r/AA0m20c4cAqiqX+ykKknSyAwbBHe3lyTpGLNoECQ5\nu6qeqKrNoypIkjRaSx0j+MTcSJKPd1yLJGkMlgqC+U8UO7fLQiRJ47FUENQhxiVJx4ilDha/Oskz\nDLYMTmzjtOmqqpd1Wp0kqXOLBkFVrTjSD05yAoPnGr+4ref2qnp3u331LcBq4D7gp6vq2UN/kiSp\nS4fzPILD9S3gkqp6NXA+8IYkFwHvAW6sqnXA3wDXdViDJGkJnQVBDXytTR7XXgVcAtze2jcDV3dV\ngyRpaV1uEZBkRZJdwAEG9yn6PPB0VT3XZtkHnNllDZKkxXUaBFX1nao6HziLwQPrX7nQbAstm2RD\nkpkkM7Ozs12WKUm91mkQzKmqp4HPABcxeKbB3EHqs4AnD7HMpqqarqrpqampUZQpSb3UWRAkmUqy\nqo2fCLwe2A3cA1zTZlsPbOmqBknS0oa96dyRWANsbs8zeBFwa1XdleRh4JYk/xm4H7ipwxokSUvo\nLAiq6nPABQu0P87geIEkaRnocotAPTOupzhJemFGcrBYkrR8GQSS1HMGgST1nEEgST1nEEhSzxkE\nktRzBoEk9ZxBIEk9ZxBIUs8ZBJLUcwaBJPWcQSBJPWcQSFLPGQSS1HMGgST1nEEgST3X5TOLX5Hk\nniS7kzyU5G2tfXWSbUn2tOEpXdUgSVpal1sEzwH/oapeCVwEvDXJq4CNwPaqWgdsb9OSpDHpLAiq\nan9V3dfG/xbYDZwJXAVsbrNtBq7uqgZJ0tJGcowgyVoGD7LfAZxRVfthEBbA6aOoQZK0sM6DIMlL\ngI8D11fVM4ex3IYkM0lmZmdnuytQknqu0yBIchyDEPhIVd3Rmp9Ksqa9vwY4sNCyVbWpqqaranpq\naqrLMiWp17o8ayjATcDuqnrfvLe2Auvb+HpgS1c1SJKWtrLDz74Y+GnggSS7Wtu7gBuAW5NcBzwB\nvKnDGiRJS+gsCKrqz4Ac4u1Lu1qvJOnweGWxJPWcQSBJPWcQSFLPGQSS1HMGgST1XJenj2pM1m68\ne9wlSJogbhFIUs8ZBJLUcwaBJPWcQSBJPWcQSFLPGQSS1HMGgST1nEEgST1nEEhSzxkEktRzBoEk\n9VyXzyz+3SQHkjw4r211km1J9rThKV2tX5I0nC63CP4H8IaD2jYC26tqHbC9TUuSxqizIKiqPwX+\n+qDmq4DNbXwzcHVX65ckDWfUxwjOqKr9AG14+qFmTLIhyUySmdnZ2ZEVKEl9s2wPFlfVpqqarqrp\nqampcZcjScesUQfBU0nWALThgRGvX5J0kFEHwVZgfRtfD2wZ8folSQfp8vTRm4H/DZyXZF+S64Ab\ngMuS7AEua9OSpDHq7JnFVfXmQ7x1aVfrlCQdvmV7sFiSNBoGgST1nEEgST1nEEhSzxkEktRzBoEk\n9ZxBIEk9ZxBIUs8ZBJLUcwaBJPWcQSBJPWcQSFLPdXbTub5bu/HucZcgSUNxi0CSes4gkKSeMwgk\nqefGEgRJ3pDk0SSPJdk4jhokSQMjP1icZAXw3xk8qnIf8NkkW6vq4S7W50FbSVrcOLYIXgM8VlWP\nV9WzwC3AVWOoQ5LEeILgTOCL86b3tTZJ0hiM4zqCLNBWf2+mZAOwoU1+LcmjB81yGvBXR7m2cTrW\n+gPHXp/sz/J3TPUp73nB/fneYWYaRxDsA14xb/os4MmDZ6qqTcCmQ31Ikpmqmj765Y3HsdYfOPb6\nZH+Wv2OtT6Pqzzh2DX0WWJfknCTHA9cCW8dQhySJMWwRVNVzSf4d8ClgBfC7VfXQqOuQJA2M5V5D\nVfVJ4JMv8GMOudtoQh1r/YFjr0/2Z/k71vo0kv6k6u8dp5Uk9Yi3mJCknluWQZDkFUnuSbI7yUNJ\n3tbaVyfZlmRPG57S2pPkt9otKz6X5MLx9uD/l+SEJPcm+YvWn19v7eck2dH687F28JwkL27Tj7X3\n146z/sUkWZHk/iR3temJ7VOSvUkeSLIryUxrm8jv3Jwkq5LcnuSR9nt67aT2Kcl57f/N3OuZJNdP\nan/mJPml9nfhwSQ3t78Xo/0dVdWyewFrgAvb+EuB/wO8CvgvwMbWvhF4Txu/HPgDBtcoXATsGHcf\nDupPgJe08eOAHa3OW4FrW/sHgX/bxn8B+GAbvxb42Lj7sEjf3g58FLirTU9sn4C9wGkHtU3kd25e\n/ZuBn2vjxwOrJr1PrdYVwJcZnCc/sf1hcDHtF4AT2/StwL8a9e9o7P8hhvyPtYXBvYkeBda0tjXA\no238Q8Cb583/3fmW2ws4CbgP+McMLhRZ2dpfC3yqjX8KeG0bX9nmy7hrX6AvZwHbgUuAu9oPbmL7\ndIggmNjvHPCy9kcmB7VPbJ/m1fZjwJ9Pen94/k4Lq9vv4i7gn436d7Qsdw3N1zZ9LmDwr+gzqmo/\nQBue3mZb9retaLtQdgEHgG3A54Gnq+q5Nsv8mr/bn/b+V4FTR1vxUN4P/DLwd236VCa7TwX8UZKd\nGVzZDhP8nQPOBWaB32u7734nyclMdp/mXAvc3MYntj9V9SXgvcATwH4Gv4udjPh3tKyDIMlLgI8D\n11fVM4vNukDbsjodqqq+U1XnM/hX9GuAVy40Wxsu+/4k+XHgQFXtnN+8wKwT0yfg4qq6EHgj8NYk\nP7LIvJPQn5XAhcAHquoC4OsMdp0cyiT0iba//ErgtqVmXaBtWfWnHc+4CjgH+B7gZAbfv4N1+jta\ntkGQ5DgGIfCRqrqjNT+VZE17fw2Df13DkLetWA6q6mngMwz2Wa5KMnctx/yav9uf9v7Lgb8ebaVL\nuhi4MsleBneQvYTBFsLE9qmqnmzDA8CdDAJ7kr9z+4B9VbWjTd/OIBgmuU8w+EN5X1U91aYnuT+v\nB75QVbNV9W3gDuCHGPHvaFkGQZIANwG7q+p9897aCqxv4+sZHDuYa/+ZdpbARcBX5zYVl4MkU0lW\ntfETGfzP3w3cA1zTZju4P3P9vAb442o7BZeLqnpnVZ1VVWsZbKb/cVW9hQntU5KTk7x0bpzBPugH\nmdDvHEBVfRn4YpLzWtOlwMNMcJ+aN/P8biGY7P48AVyU5KT2d2/u/9Fof0fjPlhyiAMoP8xgc+dz\nwK72upzBvrDtwJ42XN3mD4OH3XweeACYHncfDurP9wP3t/48CPxqaz8XuBd4jMFm7otb+wlt+rH2\n/rnj7sMS/Xsdz581NJF9anX/RXs9BPyn1j6R37l5/TofmGnfvU8Ap0xynxicbPEV4OXz2ia2P63O\nXwceaX8bPgy8eNS/I68slqSeW5a7hiRJo2MQSFLPGQSS1HMGgST1nEEgST1nEEhSzxkEktRzBoEk\n9dz/Aw9wHO+0iOhhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c172e16d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['gre'].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, these two variables' distributions are relatively normal (though gpa is skewed slightly left and seems almost bimodal because of what looks like a large count of 4.0 gpas, it still roughly resembles the normal distribution, and we're going to treat this variable as if it were normal in our analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3a. How might outliers impact your analysis? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer: While logistic regression is considered somewhat robust to influence from outliers, if there are outliers that are significantly influencing the model, we could expect errors in both our coefficient estimates and any inferences made from our analysis.\n",
    "\n",
    "It is worth noting, before even checking for outliers, that both of our continuous variables are bounded (gpa will be between 0 and 4, gre maximum is at 800), so the risk of extreme outliers influencing our model appears relatively small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3b. How will you test for outliers? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: An outlier for the gre and gpa variables will be defined as an observation that is more than 2 standard deviations from the mean value of said variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4a. What is collinearity? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer: Collinearity occurs when there are high correlations between predictor variables. This can create numerous problems for our analysis, the chief one stated well on [Wikipedia](https://en.wikipedia.org/wiki/Multicollinearity#Remedies_for_multicollinearity):\n",
    "\n",
    ">In the presence of multicollinearity, the estimate of one variable's impact on the dependent variable Y while controlling for the others tends to be less precise than if predictors were uncorrelated with one another. The usual interpretation of a regression coefficient is that it provides an estimate of the effect of a one unit change in an independent variable, X_1, holding the other variables constant. If X_1 is highly correlated with another independent variable, X_2, in the given data set, then we have a set of observations for which X_1 and X_2 have a particular linear stochastic relationship. We don't have a set of observations for which all changes in X_1 are independent of changes in X_2, so we have an imprecise estimate of the effect of independent changes in X_1.\n",
    "\n",
    "In the simplest terms, collinearity in our data would result in innacurate estimates of the effect each of our predictor variables have on the outcome variable because the predictor variables would not be independent of one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4b. How will you test for colinearity? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: There are multiple ways to check for collinearity. A few useful things to do in this analysis to test/correct for collinearity would be:\n",
    "1. Check if the standard errors of our predictor coefficients are large\n",
    "2. Make sure all categorical variables included in our model have been correctly coded as dummy variables, and do not include all categories (avoiding the \"dummy variable trap\")\n",
    "3. Cross-validate: take two independent subsets of our data, build the model on one subset, and confirm predictions are valid for the second subset\n",
    "4. Try dropping variables from our model and see how that affects predictive power, as well as what effect that has on other predictor's coefficients and standard errors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What is your exploratory analysis plan?\n",
    "Using the above information, write an exploratory analysis plan that would allow you or a colleague to reproduce your analysis 1 year from now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Set *all* things we possibly can to be equal. This means:\n",
    " - Make the dataset used in this exploratory analysis readily available to person reproducing our work\n",
    " - Note all versions of tools we are using to run this analysis (Python version number as well as the version number of any libraries utilized)\n",
    " - Set the seed early and obviously in the code that is to be reproduced\n",
    "\n",
    "\n",
    "#### 2. Follow these steps for the exploratory data analysis:\n",
    " 1. Assess the overall structure of our data (column names, datatypes, number of observations)\n",
    " 2. Check data for null values; remove any incomplete observations\n",
    " 3. Return count and frequency data for our binary/categorical variables\n",
    " 4. Create histograms for continuous variables to assess their distributions\n",
    " 5. Check for any outliers in continuous variables (+/- 2 standard deviations from the mean); remove any outliers\n",
    " 6. Create dummy variable for any predictors that are categorical (prestige in this case)\n",
    " 7. Run logistic regression on our outcome variable (admit) using gre, gpa, and prestige as predictors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Questions:\n",
    "### 1. Outline your analysis method for predicting your outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Analysis method will be logistic regression with admit as the outcome variable and gre, gpa, and prestige as the covariates/predictors.\n",
    "\n",
    "Let's just go ahead and build it (working with help from the [yhat tutorial](http://blog.yhat.com/posts/logistic-regression-and-python.html) on logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First some real quick descriptives and exploratory data analysis\n",
    "\n",
    "# Size of our df\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 400 observations of 4 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admit', 'gre', 'gpa', 'prestige']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see what those variables are\n",
    "\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit         int64\n",
       "gre         float64\n",
       "gpa         float64\n",
       "prestige    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And the data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit       0\n",
       "gre         2\n",
       "gpa         2\n",
       "prestige    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Any null values in our dataset?\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few, let's go ahead and get rid of any observations with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(axis = 0, how = 'any', inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prestige</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "      <td>55</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>53</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>61</td>\n",
       "      <td>148</td>\n",
       "      <td>121</td>\n",
       "      <td>67</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prestige  1.0  2.0  3.0  4.0  All\n",
       "admit                            \n",
       "0          28   95   93   55  271\n",
       "1          33   53   28   12  126\n",
       "All        61  148  121   67  397"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see some frequency data of admittance rates by school prestige\n",
    "pd.crosstab(df['admit'], df['prestige'], margins = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gre</th>\n",
       "      <td>397.0</td>\n",
       "      <td>587.858942</td>\n",
       "      <td>115.717787</td>\n",
       "      <td>220.00</td>\n",
       "      <td>520.00</td>\n",
       "      <td>580.0</td>\n",
       "      <td>660.00</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpa</th>\n",
       "      <td>397.0</td>\n",
       "      <td>3.392242</td>\n",
       "      <td>0.380208</td>\n",
       "      <td>2.26</td>\n",
       "      <td>3.13</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.67</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count        mean         std     min     25%    50%     75%    max\n",
       "gre  397.0  587.858942  115.717787  220.00  520.00  580.0  660.00  800.0\n",
       "gpa  397.0    3.392242    0.380208    2.26    3.13    3.4    3.67    4.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's check descriptives for our continuous variables\n",
    "df[['gre', 'gpa']].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means (gre, gpa): 587.858942065 3.3922418136\n",
      "Stds (gre, gpa): 115.717787375 0.380208292149\n"
     ]
    }
   ],
   "source": [
    "# And check for outliers (we'll use 2 standard deviations from the mean)\n",
    "mean_gre, mean_gpa = df[['gre', 'gpa']].mean()\n",
    "std_gre, std_gpa = df[['gre', 'gpa']].std()\n",
    "\n",
    "print \"Means (gre, gpa):\", mean_gre, mean_gpa\n",
    "print \"Stds (gre, gpa):\", std_gre, std_gpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRE range: 356.423367315 to 819.294516816\n",
      "GPA range: 2.6318252293 to 4.1526583979\n"
     ]
    }
   ],
   "source": [
    "gre_lo = mean_gre - (2 * std_gre)\n",
    "gre_hi = mean_gre + (2 * std_gre)\n",
    "\n",
    "gpa_lo = mean_gpa - (2 * std_gpa)\n",
    "gpa_hi = mean_gpa + (2 * std_gpa)\n",
    "\n",
    "print \"GRE range:\", gre_lo, \"to\", gre_hi\n",
    "print \"GPA range:\", gpa_lo, \"to\", gpa_hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looks like we've got a few outliers at the low ends. Let's drop them\n",
    "df = df[(df['gre'] > 356.0) & (df['gpa'] > 2.63)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1c17323790>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1c19974c90>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x1c199a13d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1c19a08990>]], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAJPCAYAAABPd8HBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nswxcZJmZmZll8H+d4H3EsWaFiwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c19898150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's take a quick look at our data distros\n",
    "df.hist(figsize = (10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prestige_1.0  prestige_2.0  prestige_3.0  prestige_4.0\n",
       "0             0             0             1             0\n",
       "1             0             0             1             0\n",
       "2             1             0             0             0\n",
       "3             0             0             0             1\n",
       "4             0             0             0             1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now to build a logistic regression model. First create a dummy variable for prestige and join back into data\n",
    "prestige_dummy = pd.get_dummies(df['prestige'], prefix='prestige')\n",
    "prestige_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit    gre   gpa  prestige_2.0  prestige_3.0  prestige_4.0\n",
       "0      0  380.0  3.61             0             1             0\n",
       "1      1  660.0  3.67             0             1             0\n",
       "2      1  800.0  4.00             0             0             0\n",
       "3      1  640.0  3.19             0             0             1\n",
       "4      0  520.0  2.93             0             0             1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the columns we want from df and dummy (dropping original prestige as well as 'prestige_1' dummy)\n",
    "df_full = df[['admit', 'gre', 'gpa']].join(prestige_dummy.loc[:, 'prestige_2':])\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit    gre   gpa  prestige_2.0  prestige_3.0  prestige_4.0  intercept\n",
       "0      0  380.0  3.61             0             1             0        1.0\n",
       "1      1  660.0  3.67             0             1             0        1.0\n",
       "2      1  800.0  4.00             0             0             0        1.0\n",
       "3      1  640.0  3.19             0             0             1        1.0\n",
       "4      0  520.0  2.93             0             0             1        1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And create an intercept for some reason (apparently a requirement of statsmodels is explicitly stated intercepts/constants)\n",
    "df_full['intercept'] = 1.0\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.578581\n",
      "         Iterations 5\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "train_cols = df_full.columns[1:] # This is all cols except admit\n",
    "\n",
    "logit = sm.Logit(df_full['admit'], df_full[train_cols]) # Note to self: the syntax here\n",
    "\n",
    "model = logit.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  admit   No. Observations:                  379\n",
      "Model:                          Logit   Df Residuals:                      373\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Thu, 01 Feb 2018   Pseudo R-squ.:                 0.07912\n",
      "Time:                        15:58:46   Log-Likelihood:                -219.28\n",
      "converged:                       True   LL-Null:                       -238.12\n",
      "                                        LLR p-value:                 4.371e-07\n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "gre              0.0024      0.001      2.085      0.037       0.000       0.005\n",
      "gpa              0.8264      0.356      2.324      0.020       0.129       1.523\n",
      "prestige_2.0    -0.7295      0.326     -2.241      0.025      -1.368      -0.091\n",
      "prestige_3.0    -1.3154      0.351     -3.750      0.000      -2.003      -0.628\n",
      "prestige_4.0    -1.5238      0.424     -3.597      0.000      -2.354      -0.694\n",
      "intercept       -4.1423      1.259     -3.289      0.001      -6.611      -1.674\n",
      "================================================================================\n",
      "\n",
      "Odds Ratios\n",
      "gre             1.002385\n",
      "gpa             2.285029\n",
      "prestige_2.0    0.482139\n",
      "prestige_3.0    0.268367\n",
      "prestige_4.0    0.217873\n",
      "intercept       0.015887\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Now let's get all the stats\n",
    "\n",
    "print model.summary() # Produces nice table\n",
    "print\n",
    "print \"Odds Ratios\"\n",
    "print np.exp(model.params) # Gives us our odds ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to interpret our odds ratios for our continuous variables:\n",
    " - Both gpa and gre have odds ratios > 1; this indicates that as those variables increase, so does the probability of admittance \n",
    " - For gre, we can read this as: for each 1 point increase in one's GRE score, the odds of admittance increase by .24% (it is worth noting that since this holds for any one point difference, this relationship is exponential, rather than linear -- that is, to compare two scores that are 5 points apart, the odds of admittance for the higher score would not be low_score_odds + (5 x .0024 x low_score_odds), but rather low_score_odds x (1.0024 ^ 5)) \n",
    " - For GPA: for a 1 point increase in gpa, the odds of admittance increase by about 128%\n",
    " \n",
    "And for our categorical variable prestige, we see marked drops in odds of admittance for any rank that is not 1:\n",
    " - The odds of a canditate from a prestige \"2\" school getting admitted to the program are roughly halved (.48) from the odds of a prestige \"1\" candidate with the same gre scores and gpa\n",
    " - For prestige \"3\" and \"4\", the odds of admittance compared to a prestige \"1\" drop by about 3/4 (to .27 the odds of a prestige \"1\" admit) and 4/5 (.22) respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>596.147757</td>\n",
       "      <td>3.424987</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>596.147757</td>\n",
       "      <td>3.424987</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>596.147757</td>\n",
       "      <td>3.424987</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>596.147757</td>\n",
       "      <td>3.424987</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          gre       gpa  prestige\n",
       "0  596.147757  3.424987         1\n",
       "1  596.147757  3.424987         2\n",
       "2  596.147757  3.424987         3\n",
       "3  596.147757  3.424987         4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For a little illustration of the impact that prestige has on probability of admittance, let's create\n",
    "# some sample data for candidates with average candidate gre scores and gpas, but each with a different \"prestige\"\n",
    "# rank for undergrad and see what our model predicts their probability of acceptance to be\n",
    "\n",
    "mean_gpa, mean_gre = df_full[['gpa', 'gre']].mean()\n",
    "\n",
    "candidates = [[mean_gre, mean_gpa, 1],     # Prestige rank \"1\" candidate\n",
    "              [mean_gre, mean_gpa, 2],     # Prestige \"2\"\n",
    "              [mean_gre, mean_gpa, 3],     # Prestige \"3\"\n",
    "              [mean_gre, mean_gpa, 4]]     # Prestige \"4\"\n",
    "\n",
    "can_df = pd.DataFrame(candidates)\n",
    "can_df.columns = [\"gre\", \"gpa\", \"prestige\"]\n",
    "\n",
    "can_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_2</th>\n",
       "      <th>prestige_3</th>\n",
       "      <th>prestige_4</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>596.147757</td>\n",
       "      <td>3.424987</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>596.147757</td>\n",
       "      <td>3.424987</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>596.147757</td>\n",
       "      <td>3.424987</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>596.147757</td>\n",
       "      <td>3.424987</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          gre       gpa  prestige_2  prestige_3  prestige_4  intercept\n",
       "0  596.147757  3.424987           0           0           0        1.0\n",
       "1  596.147757  3.424987           1           0           0        1.0\n",
       "2  596.147757  3.424987           0           1           0        1.0\n",
       "3  596.147757  3.424987           0           0           1        1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the data consistent to predict\n",
    "\n",
    "# Note: prestige must be \"dummified\", or there's a conflict w/ dtypes when predicting (dummy creates uint8 dtype?)\n",
    "dummy_ranks = pd.get_dummies(can_df['prestige'], prefix='prestige')\n",
    "can_df = can_df[['gre', 'gpa']].join(dummy_ranks.loc[:, 'prestige_2':])\n",
    "\n",
    "# Add intercept\n",
    "can_df['intercept'] = 1.0\n",
    "\n",
    "can_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_prestige</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_2</th>\n",
       "      <th>prestige_3</th>\n",
       "      <th>prestige_4</th>\n",
       "      <th>intercept</th>\n",
       "      <th>admit_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prestige '1' Candidate</td>\n",
       "      <td>596.147757</td>\n",
       "      <td>3.424987</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.526955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prestige '2' Candidate</td>\n",
       "      <td>596.147757</td>\n",
       "      <td>3.424987</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.349418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prestige '3' Candidate</td>\n",
       "      <td>596.147757</td>\n",
       "      <td>3.424987</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.230148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prestige '4' Candidate</td>\n",
       "      <td>596.147757</td>\n",
       "      <td>3.424987</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.195302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       candidate_prestige         gre       gpa  prestige_2  prestige_3  \\\n",
       "0  Prestige '1' Candidate  596.147757  3.424987           0           0   \n",
       "1  Prestige '2' Candidate  596.147757  3.424987           1           0   \n",
       "2  Prestige '3' Candidate  596.147757  3.424987           0           1   \n",
       "3  Prestige '4' Candidate  596.147757  3.424987           0           0   \n",
       "\n",
       "   prestige_4  intercept  admit_pred  \n",
       "0           0        1.0    0.526955  \n",
       "1           0        1.0    0.349418  \n",
       "2           0        1.0    0.230148  \n",
       "3           1        1.0    0.195302  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict admit probability for our 4 hypothetical candidates\n",
    "can_df['admit_pred'] = model.predict(can_df.as_matrix())\n",
    "\n",
    "ranks = [\"Prestige '1' Candidate\", \"Prestige '2' Candidate\", \"Prestige '3' Candidate\", \"Prestige '4' Candidate\"]\n",
    "can_df.insert(loc = 0, column='candidate_prestige', value=ranks)\n",
    "\n",
    "can_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from this how the probability of admittance (admit_pred) drops considerably as the prestige rank of a candidate's undergrad is lowered. These predictions also nicely illustrate the relationship between our predicted outcome (probability of admittance) and the odds ratio from our model summary.\n",
    " - The odds of admittance for a standard prestige 1 candidate are .53 / (1 - .53), or 1.13\n",
    " - The odds of admittance for a standard prestige 2 candidate are .35 / (1 - .35), or .54\n",
    " - This gives us the odds ratio (.54 / 1.13) of .48 when comparing a prestige 2 candidate with a prestige 1 candidate (and same procedure can be followed for a prestige 3 or prestige 4 candidate in comparison to prestige 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2. Write an alternative problem statement for your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Correctly categorize the prestige ranking of a candidate's undergraduate schooling from data on the individual's GRE score, GPA, and whether or not they were admitted to a graduate program, using the UCLA admissions dataset. The dataset is made up of hypothetical data (source data can be obtained [here](https://stats.idre.ucla.edu/stat/data/binary.csv); more information available at https://stats.idre.ucla.edu/r/dae/logit-regression/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Articulate the assumptions and risks of the alternative model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The main assumption would be that continuous variables in our model are approximately normally distributed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
